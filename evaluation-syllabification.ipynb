{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook contains the evaluation metrics for [`Rantanplan`](https://pypi.org/project/rantanplan/0.4.3/) v0.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run: June 17 2020 - 23:05:22\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(f\"Last run: {datetime.utcnow().strftime('%B %d %Y - %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation of necessary libaries and loading the reference corpus [EDFU](https://github.com/linhd-postdata/edfu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas numpy \"spacy<2.3.0\" spacy_affixes\n",
    "!pip install -q https://github.com/linhd-postdata/averell/archive/develop.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out _\n",
    "python -m spacy download es_core_news_md \n",
    "python -m spacy_affixes download es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"rantanplan==0.4.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDFU corpus contains 106353 syllabified words\n"
     ]
    }
   ],
   "source": [
    "edfu = requests.get(\"https://github.com/linhd-postdata/edfu/blob/v1.0.0/edfu.json?raw=true\").json()\n",
    "with open(\"edfu.txt\", \"w\") as file:\n",
    "    file.write(\"\\n\".join(edfu.keys()))\n",
    "print(f\"EDFU corpus contains {len(edfu)} syllabified words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agirrezabal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agirrezabal's syllabification system is a finite state machine written in [_foma_](https://fomafst.github.io/), which is available for most OS's. We will use the native package in Ubuntu after being instaled via `apt` (it also installs the `flookup` tool):\n",
    "```bash\n",
    "$ sudo apt install -y foma\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --out _\n",
    "# downloads a foma script for Spanish syllabification\n",
    "wget -q -O silabaEs.script https://bitbucket.org/manexagirrezabal/syllabification_gold_standard/raw/master/ruleSyllabifiers/silabaEs.script\n",
    "# compiles the foma script\n",
    "foma -q -f silabaEs.script\n",
    "# runs foma on the words in EDFU\n",
    "cat edfu.txt | flookup -ix silabaEs.fst > agirrezabal_edfu.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"agirrezabal_edfu.txt\", \"r\") as manex_file:\n",
    "    lines = manex_file.read().replace(\".\", \"-\").split(\"\\n\")\n",
    "    agirrezabal_edfu = {line.replace(\"-\", \"\"): line for line in lines if line.strip()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on EDFU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agirrezabal on EDFU: 0.9807\n"
     ]
    }
   ],
   "source": [
    "correct = sum(agirrezabal_edfu[key] == edfu[key] for key in edfu)\n",
    "agirrezabal_edfu_accuracy = correct / len(edfu)\n",
    "print(f\"Agirrezabal on EDFU: {agirrezabal_edfu_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navarro-Colorado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Navarro-Colorado's system is not packaged and therefore the syllabification algorithm is not exposed, we'll use the Docker image to work around this limitation with a custom script (it will take a long time, almost a day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navarro_colorado_syllabification = \"from modules.escansion import *; [print(AnalizaSilabas.analizaSilabas(AnalizaCategoriaGramaticalFreeling.Analiza(verso=modernizaTexto(word))).lower()) for word in open('/data/edfu.txt').read().split()];\"\n",
    "navarro_colorado_edfu = ! docker run -v $(pwd):/data linhdpostdata/adso python3 -c \"{navarro_colorado_syllabification}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on EDFU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = sum(navarro_colorado_edfu[index] == edfu[key] for index, key in enumerate(edfu.keys()))\n",
    "navarro_colorado_edfu_accuracy = correct / len(edfu)\n",
    "print(f\"Navarro-Colorado on EDFU: {navarro_colorado_edfu_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rantanplan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rantanplan.core import syllabify\n",
    "\n",
    "rantanplan_edfu = [\"-\".join(syllabify(word)[0]) for word in edfu.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on EDFU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = sum(rantanplan_edfu[index] == edfu[key] for index, key in enumerate(edfu))\n",
    "rantanplan_edfu_accuracy = correct / len(edfu)\n",
    "print(f\"Rantanplan on on EDFU: {rantanplan_edfu_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\n",
    "    pd.DataFrame([\n",
    "        [\"Navarro-Colorado\", navarro_colorado_edfu_accuracy],\n",
    "        [\"Agirrezabal\", agirrezabal_edfu_accuracy],\n",
    "        [\"Rantanplan\", rantanplan_edfu_accuracy],\n",
    "    ], columns=[\"Model\", \"Accuracy\"]).to_html(index=False)\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
